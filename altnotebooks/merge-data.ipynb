{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import googlemaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# read in cleaned data sets\n",
    "\n",
    "\n",
    "df1 = pd.read_csv('../data/alt/csv/sampled_wells_cleaned.csv', converters={'id': lambda x: str(x.strip()),\n",
    "                                                                'zip': lambda x: str(x.strip()),\n",
    "                                                                'city': lambda x: str(x.strip()),\n",
    "                                                                'add': lambda x: str(x.strip())})\n",
    "\n",
    "df2 = pd.read_csv('../data/alt/csv/permitted_wells_cleaned.csv', converters={'id': lambda x: str(x.strip()),\n",
    "                                                                'zip': lambda x: str(x.strip()),\n",
    "                                                                'add_zip': lambda x: str(x.strip()),\n",
    "                                                                'city': lambda x: str(x.strip()),\n",
    "                                                                'add': lambda x: str(x.strip())})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joins df2 to df1 on the following columns. \n",
    "\n",
    "df2 = df2[['id', 'X', 'Y']]\n",
    "\n",
    "ar = pd.merge(df1, df2, on='id', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "add            1687\n",
       "city           1687\n",
       "zip            1687\n",
       "id             1687\n",
       "date           1687\n",
       "ar             1687\n",
       "ph             1687\n",
       "sample_id      1687\n",
       "date_tested    1687\n",
       "year_tested    1687\n",
       "group          1687\n",
       "group_five     1687\n",
       "group_mcl      1687\n",
       "X               718\n",
       "Y               718\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checks the number of valid entries in each column\n",
    "\n",
    "ar.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates single address string for geocoding\n",
    "\n",
    "ar['full_add'] = ar['add'] + ', ' + ar['city'] + ', ' + 'NC ' + ar['zip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X    969\n",
       "Y    969\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checks the number of missing values in the new columns\n",
    "\n",
    "ar[['X', 'Y']].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = ar[['id','full_add', 'date_tested', 'year_tested', 'X', 'Y', 'ar', 'group', 'group_five', 'group_mcl', 'ph']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "972 samples  will have to be geocoded using the Google Maps API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "geoX    0\n",
       "geoY    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_key = \"AIzaSyD4MWa0YgnE8mvIIxxTqJzMbzqippwbOFs\"\n",
    "gmaps_key = googlemaps.Client(key=api_key)\n",
    "\n",
    "# geocodes useing full address ('full_add') for the ar dataframe, \n",
    "# outputs X and Y coordinates into seperate new geoX and geoY columns\n",
    "# the geocode function will use the googlemaps library and geocode api to geocode the addresses\n",
    "\n",
    "def geocode(row):\n",
    "    try:\n",
    "        result = gmaps_key.geocode(row['full_add'])\n",
    "        geoX = result[0]['geometry']['location']['lng']\n",
    "        geoY = result[0]['geometry']['location']['lat']\n",
    "        return pd.Series([geoX, geoY])\n",
    "    except:\n",
    "        return pd.Series([np.nan, np.nan])\n",
    "\n",
    "# applies the geocode function to the ar dataframe\n",
    "# the geocode function will create two new columns, geoX and geoY, in the ar dataframe\n",
    "\n",
    "ar[['geoX', 'geoY']] = ar.apply(geocode, axis=1)\n",
    "\n",
    "# check the number of missing values in the new columns\n",
    "\n",
    "ar[['geoX', 'geoY']].isnull().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar['sample_id'] = ar.index\n",
    "\n",
    "ar.to_csv(\"../data/alt/gis/point/ar_samples.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "58a2e68265e5871579dff07da96778d0132892d6744ab693af39e5915174ef8e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
