{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import googlemaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# read in cleaned data sets\n",
    "\n",
    "\n",
    "df1 = pd.read_csv('./data/permit_data_cleaned.csv', converters={'id': lambda x: str(x.strip()),\n",
    "                                                                'zip': lambda x: str(x.strip()),\n",
    "                                                                'add_zip': lambda x: str(x.strip()),\n",
    "                                                                'city': lambda x: str(x.strip()),\n",
    "                                                                'add': lambda x: str(x.strip())})\n",
    "\n",
    "\n",
    "\n",
    "df2 = pd.read_csv('./data/well_data_cleaned.csv', converters={'id': lambda x: str(x.strip()),\n",
    "                                                                'zip': lambda x: str(x.strip()),\n",
    "                                                                'city': lambda x: str(x.strip()),\n",
    "                                                                'add': lambda x: str(x.strip())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join df2 to df1 on the following columns\n",
    "# columns of interest are \"add\",\"city\",\"zip\",\"permitno\",\"date\",\"ar\",\"ph\" from df2\n",
    "# the keys to join on in df1 are \"add\"\"\n",
    "# keys to join on from df2 are \"add\"\n",
    "# all columns from df2 should be joined to df1\n",
    "\n",
    "\n",
    "#df3 = pd.merge(df1, df2, on='add', how='left')\n",
    "\n",
    "all_wells = pd.merge(df1, df2, on='id', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id            8145\n",
       "add_zip       8145\n",
       "city_x        8145\n",
       "zip_x         8145\n",
       "X             8145\n",
       "Y             8145\n",
       "depth         7834\n",
       "perm_date     8034\n",
       "add_x         8145\n",
       "year_built    8034\n",
       "add_y          726\n",
       "city_y         726\n",
       "state          726\n",
       "zip_y          726\n",
       "altid          726\n",
       "date           726\n",
       "ar             726\n",
       "ph             726\n",
       "group          726\n",
       "group_five     726\n",
       "year           726\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the number of valid entries in each column\n",
    "\n",
    "all_wells.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_wells.rename(columns={'date': 'date_sampled', 'city_x': 'city', 'zip_x': 'zip', 'add_x': 'add', 'year': 'year_sampled'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_wells['full_add'] = all_wells['add'] + ', ' + all_wells['city'] + ', ' + 'NC ' + all_wells['zip']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "709"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar = all_wells[all_wells['group_five'] < 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X    0\n",
       "Y    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the number of missing values in the new columns\n",
    "\n",
    "ar[['X', 'Y']].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = ar[['id','full_add', 'year_built','date_sampled', 'year_sampled', 'X', 'Y', 'ar', 'group', 'group_five', 'depth', 'ph']]\n",
    "\n",
    "all_wells = all_wells[['id','full_add', 'year_built','date_sampled', 'year_sampled', 'X', 'Y', 'ar', 'group', 'group_five', 'depth', 'ph']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data for samples and newly built wells after 2017 will have to be geocoded, return once full data is obtained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#api_key = \"AIzaSyD4MWa0YgnE8mvIIxxTqJzMbzqippwbOFs\"\n",
    "#gmaps_key = googlemaps.Client(key=api_key)\n",
    "\n",
    "# create a geocode function that uses full address ('full_add') for the well dataframe, \n",
    "# outputs X and Y coordinates into seperate new geoX and geoY columns\n",
    "# the geocode function will use the googlemaps library and geocode api to geocode the addresses\n",
    "\n",
    "#def geocode(row):\n",
    "#    try:\n",
    "#        result = gmaps_key.geocode(row['full_add'])\n",
    "#        geoX = result[0]['geometry']['location']['lng']\n",
    "#        geoY = result[0]['geometry']['location']['lat']\n",
    "#        return pd.Series([geoX, geoY])\n",
    "#    except:\n",
    "#        return pd.Series([np.nan, np.nan])\n",
    "\n",
    "# apply the geocode function to the well dataframe\n",
    "# the geocode function will create two new columns, geoX and geoY, in the well dataframe\n",
    "\n",
    "#well[['geoX', 'geoY']] = well.apply(geocode, axis=1)\n",
    "\n",
    "# check the number of missing values in the new columns\n",
    "\n",
    "#well[['geoX', 'geoY']].isnull().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for records missing values for X and Y, insert the newly geocoded X and Y values into the original X and Y columns\n",
    "# thus retaining the already geocoded X and Y values for records that already have them\n",
    "\n",
    "#well['X'] = np.where(well['X'].isnull(), well['geoX'], well['X'])\n",
    "#well['Y'] = np.where(well['Y'].isnull(), well['geoY'], well['Y'])\n",
    "\n",
    "# check the number of missing values in the new columns\n",
    "\n",
    "#well[['X', 'Y']].isnull().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X    0\n",
       "Y    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop records with missing values for X and Y\n",
    "\n",
    "#well = well.dropna(subset=['X', 'Y'])\n",
    "\n",
    "# check the number of missing values in the new columns\n",
    "\n",
    "#well[['X', 'Y']].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_wells.to_csv(\"./data/all_wells_points.csv\", index=False)\n",
    "\n",
    "ar.to_csv(\"./data/ar_samples_points.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "58a2e68265e5871579dff07da96778d0132892d6744ab693af39e5915174ef8e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
