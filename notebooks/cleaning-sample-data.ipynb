{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2b7cdd8f-f83d-4ae3-b0b8-55ed8291f3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da56ca7a-8d8f-4ad8-b3d7-6ed65f70fa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"../data/csv/sampled_wells.xlsx\", converters={'Collection Date': str,\n",
    "                                                        'City': lambda x: str(x.strip()),\n",
    "                                                        'ZipCode': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f8ade33b-004b-46c7-b06f-293ae160854e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1714"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of records\n",
    "\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1e9a4b58-6be2-4b4f-98c5-74552b48b950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selects columns\n",
    "\n",
    "df = df[[\"Address\",\n",
    "         \"City\",\n",
    "         \"State\",\n",
    "         \"ZipCode\",\n",
    "         \"Well Permit #\",\n",
    "         \"Collection Date\",\n",
    "         \"Arsenic\",\n",
    "         \"pH\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae36243f-f3dc-4fd7-8065-4413da01a082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# renames columns\n",
    "\n",
    "df.columns = [\"add\",\"city\",\"state\",\"zip\",\"id\",\"date\",\"ar\",\"ph\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e8aec49b-a260-4371-b840-5833169bde45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "add        0\n",
       "city       1\n",
       "state      0\n",
       "zip        0\n",
       "id       614\n",
       "date       0\n",
       "ar        13\n",
       "ph        11\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checks for missing values\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9bce89f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ALEXIS',\n",
       " 'BELMONT',\n",
       " 'BESSEMER CITY',\n",
       " 'Bassemer City',\n",
       " 'Belmont',\n",
       " 'Bessemer City',\n",
       " 'CHERRYVILLE',\n",
       " 'CRAMERTON',\n",
       " 'CROUSE',\n",
       " 'Cherryville',\n",
       " 'Crouse',\n",
       " 'DALLAS',\n",
       " 'Dallas',\n",
       " 'GASTONIA',\n",
       " 'Gastonia',\n",
       " 'IRON STATION',\n",
       " 'KINGS MOUNTAIN',\n",
       " 'KINGS MOUTAIN',\n",
       " 'King Mtn 1Kings Mountain',\n",
       " 'Kings Mountain',\n",
       " 'LINCOLNTON',\n",
       " 'LOWEL',\n",
       " 'LOWELL',\n",
       " 'Lincolnton',\n",
       " 'MC ADENVILLE',\n",
       " 'MOUNT HOLLY',\n",
       " 'MT HOLLY',\n",
       " 'Mount Holly',\n",
       " 'Mt. Holly',\n",
       " 'PINEVILLE',\n",
       " 'STALEY',\n",
       " 'STANLEY',\n",
       " 'Stanley',\n",
       " nan}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checks for typos in city names\n",
    "\n",
    "set(df['city'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e5a4a253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "city\n",
       "GASTONIA         360\n",
       "BELMONT          285\n",
       "DALLAS           254\n",
       "MT HOLLY         183\n",
       "STANLEY          168\n",
       "BESSEMER CITY    162\n",
       "KINGS MTN         99\n",
       "CHERRYVILLE       90\n",
       "LINCOLNTON        64\n",
       "CROUSE            23\n",
       "ALEXIS            16\n",
       "LOWELL             3\n",
       "CRAMERTON          3\n",
       "PINEVILLE          1\n",
       "MCADENVILLE        1\n",
       "                   1\n",
       "IRON STATION       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# corrects typos for city\n",
    "\n",
    "li = []\n",
    "\n",
    "for each in df['city']:\n",
    "\n",
    "    if each in ['GASTONIA', 'Gastonia']:\n",
    "        li.append('GASTONIA')\n",
    "\n",
    "    elif each in ['BELMONT', 'Belmont']:\n",
    "        li.append('BELMONT')\n",
    "\n",
    "    elif each in ['DALLAS', 'Dallas']:\n",
    "        li.append('DALLAS')\n",
    "    \n",
    "    elif each in ['MOUNT HOLLY', 'Mt. Holly','MT HOLLY', 'Mount Holly']:\n",
    "        li.append('MT HOLLY')\n",
    "\n",
    "    elif each in ['STANLEY','Stanley', 'STALEY']:\n",
    "        li.append('STANLEY')\n",
    "    \n",
    "    elif each in ['BESSEMER CITY', 'Bessemer City','Bassemer City']:\n",
    "        li.append('BESSEMER CITY')\n",
    "    \n",
    "    elif each in ['KINGS MOUNTAIN', 'Kings Mountain','KINGS MOUTAIN','King Mtn 1Kings Mountain']:\n",
    "        li.append('KINGS MTN')\n",
    "    \n",
    "    elif each in['CHERRYVILLE', 'Cherryville']:\n",
    "        li.append('CHERRYVILLE')\n",
    "    \n",
    "    elif each in['LINCOLNTON','Lincolnton']:\n",
    "        li.append('LINCOLNTON')\n",
    "    \n",
    "    elif each in['IRON STATION']:\n",
    "        li.append('IRON STATION')\n",
    "\n",
    "    elif each in['ALEXIS']:\n",
    "        li.append('ALEXIS')\n",
    "\n",
    "    elif each in['LOWEL','LOWELL']:\n",
    "        li.append('LOWELL')\n",
    "\n",
    "    elif each in['CROUSE', 'Crouse']:\n",
    "        li.append('CROUSE')\n",
    "\n",
    "    elif each in['CRAMERTON']: \n",
    "        li.append('CRAMERTON')\n",
    "\n",
    "    elif each in ['MC ADENVILLE']:\n",
    "        li.append('MCADENVILLE')\n",
    "\n",
    "    elif each == 'PINEVILLE':\n",
    "        li.append('PINEVILLE')\n",
    "    else:\n",
    "        li.append(\"\")\n",
    "\n",
    "df['city'] = li\n",
    "\n",
    "df['city'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3fee6178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1713"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove leading and trailing spaces from city names\n",
    "\n",
    "df['city'] = [s.strip() for s in df['city']]\n",
    "\n",
    "# drop rows with missing city values\n",
    "\n",
    "df = df[df['city'] != '']\n",
    "\n",
    "# create index value for tracking in later merges\n",
    "\n",
    "df['sample_id'] = df.index\n",
    "\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ae04d6c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "zip\n",
       "28012    277\n",
       "28034    258\n",
       "28056    198\n",
       "28120    181\n",
       "28164    165\n",
       "28016    163\n",
       "28052    142\n",
       "28086     96\n",
       "28021     91\n",
       "28092     62\n",
       "28033     23\n",
       "28054     21\n",
       "28006     15\n",
       "28032      4\n",
       "28098      3\n",
       "28066      2\n",
       "28101      1\n",
       "29164      1\n",
       "28210      1\n",
       "28080      1\n",
       "28093      1\n",
       "2056       1\n",
       "27355      1\n",
       "28134      1\n",
       "28102      1\n",
       "28106      1\n",
       "28806      1\n",
       "28065      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check zip codes for typos (aka anything starting with 29 or not 5 digits)\n",
    "df['zip'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d6fffd62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1700"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert zip column to string\n",
    "\n",
    "df['zip'] = df['zip'].astype(str)\n",
    "\n",
    "# check city and zip for bad values\n",
    "\n",
    "valid_zips  = ['28006',\n",
    "                '28012',\n",
    "                '28016',\n",
    "                '28021',\n",
    "                '28032',\n",
    "                '28033',\n",
    "                '28034',\n",
    "                '28052',\n",
    "                '28053',\n",
    "                '28054',\n",
    "                '28055',\n",
    "                '28056',\n",
    "                '28077',\n",
    "                '28086',\n",
    "                '28092',\n",
    "                '28098',\n",
    "                '28101',\n",
    "                '28120',\n",
    "                '28164']\n",
    "\n",
    "\n",
    "# loop through dataframe and if zip is not in valid_zips list, remove row\n",
    "\n",
    "\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row['zip'] not in valid_zips:\n",
    "        df.drop(index, inplace=True)\n",
    "\n",
    "\n",
    "# check number removed\n",
    "\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e7cc88ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# check for blanks in address\n",
    "\n",
    "print(len(df[df['add'] == '']))\n",
    "print(len(df[df['add'] == ' ']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0596f033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim leading and trailing spaces from address\n",
    "\n",
    "df['add'] = [s.strip() for s in df['add']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "178c1758-44c2-44f7-adf5-19f3f9569a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts long date to short date\n",
    "\n",
    "df['date'] = df['date'].str[:10]\n",
    "df['date'] = [x.strip() for x in df['date']]\n",
    "\n",
    "df['date'] = df['date'].replace(regex=['2/1/2021'], value=\"2021-02-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c54817b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2011-01-03\n",
       "1       2011-01-04\n",
       "3       2011-01-04\n",
       "5       2011-01-24\n",
       "6       2011-01-26\n",
       "           ...    \n",
       "1709    2021-04-05\n",
       "1710    2021-02-08\n",
       "1711    2021-02-08\n",
       "1712    2021-02-15\n",
       "1713    2020-07-29\n",
       "Name: date, Length: 1700, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "94c5e138-64ad-4c8b-9d7e-e1da3b45ec60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts date to datetime\n",
    "\n",
    "df['date_tested'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7beb89d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates year column\n",
    "\n",
    "df['year_tested'] = df['date_tested'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "779b4bd3-9124-453e-a797-e7ce12d17099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts non-detect arsenic values to 0\n",
    "\n",
    "li = []\n",
    "for each in df['ar']:\n",
    "    if each in('<0.001','< 0.005', '<0.005', '<0.01'):\n",
    "        li.append(float(0))\n",
    "    else:\n",
    "        li.append(float(each))\n",
    "\n",
    "df['ar'] = li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "28c318d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "group\n",
       "0    1569\n",
       "1     131\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creates a new column to group arsenic values into 0 and 1, 0 for <0.001 and 1 for >=0.001\n",
    "\n",
    "li = []\n",
    "for each in df['ar']:\n",
    "    if each < 0.001:\n",
    "        li.append('0')\n",
    "    else: li.append('1')\n",
    "\n",
    "df['group'] = li\n",
    "\n",
    "df['group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a33d72b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "group_five\n",
       "0    1629\n",
       "1      71\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Creates a new column to group arsenic values into 0 and 1, 0 for <0.005 and 1 for >=0.005\n",
    "\n",
    "li = []\n",
    "for each in df['ar']:\n",
    "    if each < 0.005:\n",
    "        li.append('0')\n",
    "    else: li.append('1')\n",
    "\n",
    "df['group_five'] = li\n",
    "\n",
    "\n",
    "df['group_five'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "303811a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "group_mcl\n",
       "0    1656\n",
       "1      44\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Creates a new column to group arsenic values into 0 and 1, 0 for <0.005 and 1 for >=0.01  (MCL)\n",
    "\n",
    "li = []\n",
    "for each in df['ar']:\n",
    "    if each < 0.01:\n",
    "        li.append('0')\n",
    "    else: li.append('1')\n",
    "\n",
    "df['group_mcl'] = li\n",
    "\n",
    "\n",
    "df['group_mcl'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f8b0524b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1700"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "00c13bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if missing arsenic or ph values, drop the row\n",
    "\n",
    "df = df.dropna(subset=['ar','ph'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b9b5d2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saves the cleaned data to a new file in data folder\n",
    "\n",
    "df.to_csv(\"../data/csv/sampled_wells_cleaned.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "58a2e68265e5871579dff07da96778d0132892d6744ab693af39e5915174ef8e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
